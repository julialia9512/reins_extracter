# app.py
import re
import io
from datetime import datetime
import pandas as pd
from bs4 import BeautifulSoup
import streamlit as st

st.set_page_config(page_title="REINS Extractor", layout="wide")

# =========================
# å…±é€šï¼šã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ç³»
# =========================
def _get_today_yyyymmdd():
    """Returns today's date as YYYYMMDD string"""
    return datetime.now().strftime("%Y%m%d")

def _text_or_none(el):
    if not el:
        return None
    t = " ".join(el.get_text(" ", strip=True).split())
    return t or None

def _clean_price_million_yen(s: str):
    # "10,980ä¸‡å††" -> 10980
    if not s:
        return None
    s = str(s)
    # ã‚ˆãã‚ã‚‹ã€Œä¸‡ã€ã‚„ã€Œå††ã€æ··åœ¨ã®å¸å
    if "ä¸‡å††" in s:
        s = s.replace("ä¸‡å††", "")
        s = re.sub(r"[^\d.]", "", s)
        return float(s) if s else None
    # ã€Œå††ã€è¡¨è¨˜ãªã‚‰ä¸‡å††æ›ç®—
    if "å††" in s:
        yen = re.sub(r"[^\d.]", "", s)
        return float(yen) / 10000 if yen else None
    # ãŸã ã®æ•°å­—ãªã‚‰ãã®ã¾ã¾
    s = re.sub(r"[^\d.]", "", s)
    return float(s) if s else None

def _clean_area_sqm(s: str):
    # "82.04ã¡" -> 82.04
    if not s:
        return None
    m = re.search(r"([\d.]+)\s*ã¡", s)
    if not m:
        m = re.search(r"([\d.]+)", str(s))
    return float(m.group(1)) if m else None

def _clean_tsubo(sqm):
    # 1åª = 3.305785 mÂ²
    if sqm is None:
        return None
    try:
        return float(sqm) / 3.305785
    except:
        return None

def _clean_minutes(s: str):
    # "å¾’æ­© 5 åˆ†" / "å¾’æ­©ã€€5åˆ†" / "5åˆ†" -> 5
    if not s:
        return None
    digits = re.sub(r"\D", "", str(s))
    return int(digits) if digits else None

def _clean_yyyymm_from_jp(s: str):
    # "2026å¹´ï¼ˆä»¤å’Œ 8å¹´ï¼‰ 2æœˆ" -> "2026-02"
    if not s:
        return None
    y = re.search(r"(\d{4})\s*å¹´", s)
    m = re.search(r"(\d{1,2})\s*æœˆ", s)
    if y and m:
        return f"{int(y.group(1)):04d}-{int(m.group(1)):02d}"
    return None

def _clean_fee_yen_month(s: str):
    # "1ä¸‡2,000å††/æœˆ" -> 12000
    if not s:
        return None
    txt = str(s)
    # ã€Œä¸‡ã€ã‚’å«ã‚€å ´åˆ
    if "ä¸‡" in txt:
        # ä¾‹: 1.2ä¸‡å††, 1ä¸‡2,000å††
        man = re.search(r"(\d+(?:\.\d+)?)\s*ä¸‡", txt)
        sen = re.search(r"ä¸‡\s*([\d,]+)", txt)
        yen = 0.0
        if man:
            yen += float(man.group(1)) * 10000
        if sen:
            yen += float(re.sub(r"[^\d.]", "", sen.group(1)))
        if yen == 0:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            nums = re.findall(r"[\d.]+", txt)
            return float("".join(nums)) if nums else None
        return float(yen)
    # ç´”ç²‹ãªå††è¡¨è¨˜
    nums = re.sub(r"[^\d.]", "", txt)
    return float(nums) if nums else None

# =========================
# å…±é€šï¼šã‚°ãƒªãƒƒãƒ‰ãƒ†ãƒ¼ãƒ–ãƒ«è§£æ
# =========================
_grid_re = {
    "col_range": re.compile(r"grid-column:\s*(\d+)\s*/\s*span\s*(\d+)"),
    "col_start": re.compile(r"grid-column-start:\s*(\d+)"),
    "row_range": re.compile(r"grid-row:\s*(\d+)\s*/\s*span\s*(\d+)"),
    "row_start": re.compile(r"grid-row-start:\s*(\d+)"),
}

def _parse_grid_position(style: str):
    """Returns (row_start, row_end, col_start, col_end) 1-based inclusive."""
    row_start = 1; row_span = 1; col_start = 1; col_span = 1
    style = style or ""
    m = _grid_re["row_range"].search(style)
    if m:
        row_start = int(m.group(1)); row_span = int(m.group(2))
    else:
        m = _grid_re["row_start"].search(style)
        if m:
            row_start = int(m.group(1))
    m = _grid_re["col_range"].search(style)
    if m:
        col_start = int(m.group(1)); col_span = int(m.group(2))
    else:
        m = _grid_re["col_start"].search(style)
        if m:
            col_start = int(m.group(1))
    return (row_start, row_start + row_span - 1, col_start, col_start + col_span - 1)

def _build_header_cells(header_root):
    items = []
    for h in header_root.select(".p-table-header-item"):
        txt = _text_or_none(h)
        r1, r2, c1, c2 = _parse_grid_position(h.get("style", ""))
        items.append({"text": txt, "r1": r1, "r2": r2, "c1": c1, "c2": c2})
    return items

def _label_for_cell(cell_row_start, cell_col_start, header_cells):
    # ãƒ˜ãƒƒãƒ€ç¯„å›²ã«å«ã¾ã‚Œã‚‹å€™è£œã‹ã‚‰ã€æœ€ã‚‚æ·±ã„ï¼ˆr1ãŒå¤§ãã„ï¼‰ã‚‚ã®ã‚’æ¡ç”¨
    candidates = []
    for hd in header_cells:
        if hd["r1"] <= cell_row_start <= hd["r2"] and hd["c1"] <= cell_col_start <= hd["c2"]:
            if hd["text"]:
                candidates.append(hd)
    if not candidates:
        return None
    candidates.sort(key=lambda x: (x["r1"], -(x["c2"] - x["c1"])), reverse=True)
    return candidates[0]["text"]

def _rows_from_grid_table(table_root):
    header_root = table_root.select_one(".p-table-header")
    body_root = table_root.select_one(".p-table-body")
    if not header_root or not body_root:
        return []
    header_cells = _build_header_cells(header_root)
    rows = []
    for row in body_root.select(".p-table-body-row"):
        record = {}
        for td in row.select(".p-table-body-item"):
            r1, _, c1, _ = _parse_grid_position(td.get("style", ""))
            label = _label_for_cell(r1, c1, header_cells)
            val = _text_or_none(td)
            if label:
                record[label] = val  # å¾Œå‹ã¡
        rows.append(record)
    return rows

def _find_table_root(soup):
    # villaã¯ .p-table.smallã€ãƒãƒ³ã‚·ãƒ§ãƒ³ã¯ .p-table ã ã‘ã®ã“ã¨ã‚‚ã‚ã‚‹
    table = soup.select_one(".p-table.small")
    if not table:
        table = soup.select_one(".p-table")
    return table

def _find_all_tables(soup):
    """Find all tables and return them with their types (apartment/villa/unknown)"""
    # Find all potential table containers
    all_tables = soup.select(".p-table")
    
    apt_table = None
    villa_table = None
    
    for table in all_tables:
        # Get header cells to determine table type
        header_cells = []
        header_root = table.select_one(".p-table-header")
        if header_root:
            for h in header_root.select(".p-table-header-item"):
                txt = _text_or_none(h)
                if txt:
                    header_cells.append(txt)
        
        # Check if it's a villa table by looking for villa-specific columns
        villa_indicators = ["åœŸåœ°é¢ç©", "å»ºç‰©é¢ç©", "æ¥é“çŠ¶æ³", "æ¥é“ï¼‘"]
        apt_indicators = ["å°‚æœ‰é¢ç©", "å»ºç‰©å", "æ‰€åœ¨éš", "ç®¡ç†è²»"]
        
        has_villa_cols = any(ind in " ".join(header_cells) for ind in villa_indicators)
        has_apt_cols = any(ind in " ".join(header_cells) for ind in apt_indicators)
        
        if has_villa_cols and not villa_table:
            villa_table = table
        elif has_apt_cols and not apt_table:
            apt_table = table
    
    return apt_table, villa_table

# =========================
# ãƒãƒ³ã‚·ãƒ§ãƒ³/åŒºåˆ†ï¼ˆæ—¢å­˜ç³»ï¼‰
# =========================
APT_COLUMNS = [
    "No.",
    "ç‰©ä»¶ç•ªå·",
    "ç‰©ä»¶ç¨®ç›®",
    "å°‚æœ‰é¢ç© (ã¡)",
    "æ‰€åœ¨åœ°",
    "å–å¼•æ…‹æ§˜",
    "ä¾¡æ ¼ (ä¸‡å††)",
    "ç”¨é€”åœ°åŸŸ",
    "ã¡å˜ä¾¡ (ä¸‡å††/ã¡)",
    "å»ºç‰©å",
    "æ‰€åœ¨éš",
    "é–“å–",
    "å–å¼•çŠ¶æ³",
    "ç®¡ç†è²» (å††/æœˆ)",
    "åªå˜ä¾¡ (ä¸‡å††/åª)",
    "æ²¿ç·šé§…",
    "äº¤é€š (åˆ†)",
    "å•†å·",
    "ç¯‰å¹´æœˆ (YYYY-MM)",
    "é›»è©±ç•ªå·",
    "å…¥åŠ›æ—¥ (YYYYMMDD)",
]

_APT_ALIASES = {
    "No.": "No.",
    "ç‰©ä»¶ç•ªå·": "ç‰©ä»¶ç•ªå·",
    "ç‰©ä»¶ç¨®ç›®": "ç‰©ä»¶ç¨®ç›®",
    "å°‚æœ‰é¢ç©": "å°‚æœ‰é¢ç© (ã¡)",
    "æ‰€åœ¨åœ°": "æ‰€åœ¨åœ°",
    "å–å¼•æ…‹æ§˜": "å–å¼•æ…‹æ§˜",
    "ä¾¡æ ¼": "ä¾¡æ ¼ (ä¸‡å††)",
    "ç”¨é€”åœ°åŸŸ": "ç”¨é€”åœ°åŸŸ",
    "ã¡å˜ä¾¡": "ã¡å˜ä¾¡ (ä¸‡å††/ã¡)",
    "å»ºç‰©å": "å»ºç‰©å",
    "æ‰€åœ¨éš": "æ‰€åœ¨éš",
    "é–“å–": "é–“å–",
    "å–å¼•çŠ¶æ³": "å–å¼•çŠ¶æ³",
    "ç®¡ç†è²»": "ç®¡ç†è²» (å††/æœˆ)",
    "åªå˜ä¾¡": "åªå˜ä¾¡ (ä¸‡å††/åª)",
    "æ²¿ç·šé§…": "æ²¿ç·šé§…",
    "äº¤é€š": "äº¤é€š (åˆ†)",
    "å•†å·": "å•†å·",
    "ç¯‰å¹´æœˆ": "ç¯‰å¹´æœˆ (YYYY-MM)",
    "é›»è©±ç•ªå·": "é›»è©±ç•ªå·",
}

def parse_apartment_html_to_df(html: str) -> pd.DataFrame:
    soup = BeautifulSoup(html, "lxml")
    table = _find_table_root(soup)
    if not table:
        return pd.DataFrame(columns=APT_COLUMNS)
    raw_rows = _rows_from_grid_table(table)

    records = []
    for rr in raw_rows:
        rec = {k: None for k in APT_COLUMNS}
        mapped = {}
        for k, v in rr.items():
            key = _APT_ALIASES.get(k)
            if key:
                mapped[key] = v

        # æ–‡å­—åˆ—ã®ã¾ã¾å…¥ã‚Œã‚‹åˆ—
        for key in ["No.","ç‰©ä»¶ç•ªå·","ç‰©ä»¶ç¨®ç›®","æ‰€åœ¨åœ°","å–å¼•æ…‹æ§˜","ç”¨é€”åœ°åŸŸ",
                    "å»ºç‰©å","æ‰€åœ¨éš","é–“å–","å–å¼•çŠ¶æ³","æ²¿ç·šé§…",
                    "å•†å·","é›»è©±ç•ªå·"]:
            rec[key] = mapped.get(key)

        # æ•°å€¤/æ­£è¦åŒ–
        rec["ä¾¡æ ¼ (ä¸‡å††)"] = _clean_price_million_yen(mapped.get("ä¾¡æ ¼ (ä¸‡å††)"))
        rec["å°‚æœ‰é¢ç© (ã¡)"] = _clean_area_sqm(mapped.get("å°‚æœ‰é¢ç© (ã¡)"))
        rec["äº¤é€š (åˆ†)"] = _clean_minutes(mapped.get("äº¤é€š (åˆ†)"))
        rec["ç¯‰å¹´æœˆ (YYYY-MM)"] = _clean_yyyymm_from_jp(mapped.get("ç¯‰å¹´æœˆ (YYYY-MM)"))

        # ã¡å˜ä¾¡ / åªå˜ä¾¡ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã«å˜ä½æ··ã˜ã‚‹æƒ³å®šï¼‰
        unit_sqm = mapped.get("ã¡å˜ä¾¡ (ä¸‡å††/ã¡)")
        if unit_sqm:
            rec["ã¡å˜ä¾¡ (ä¸‡å††/ã¡)"] = float(re.sub(r"[^\d.]", "", unit_sqm)) if re.search(r"\d", unit_sqm) else None
        else:
            # ä¾¡æ ¼ / å°‚æœ‰é¢ç© ã‹ã‚‰é€†ç®—ï¼ˆä¸‡å††/ã¡ï¼‰
            if rec["ä¾¡æ ¼ (ä¸‡å††)"] and rec["å°‚æœ‰é¢ç© (ã¡)"]:
                rec["ã¡å˜ä¾¡ (ä¸‡å††/ã¡)"] = rec["ä¾¡æ ¼ (ä¸‡å††)"] / rec["å°‚æœ‰é¢ç© (ã¡)"]

        tsubo = _clean_tsubo(rec["å°‚æœ‰é¢ç© (ã¡)"])
        unit_tsubo = mapped.get("åªå˜ä¾¡ (ä¸‡å††/åª)")
        if unit_tsubo:
            rec["åªå˜ä¾¡ (ä¸‡å††/åª)"] = float(re.sub(r"[^\d.]", "", unit_tsubo)) if re.search(r"\d", unit_tsubo) else None
        else:
            if rec["ä¾¡æ ¼ (ä¸‡å††)"] and tsubo:
                rec["åªå˜ä¾¡ (ä¸‡å††/åª)"] = rec["ä¾¡æ ¼ (ä¸‡å††)"] / tsubo

        # ç®¡ç†è²»
        rec["ç®¡ç†è²» (å††/æœˆ)"] = _clean_fee_yen_month(mapped.get("ç®¡ç†è²» (å††/æœˆ)"))

        # å…¥åŠ›æ—¥
        rec["å…¥åŠ›æ—¥ (YYYYMMDD)"] = _get_today_yyyymmdd()

        records.append(rec)

    df = pd.DataFrame(records, columns=APT_COLUMNS)
    # ã‚­ãƒ£ã‚¹ãƒˆ
    for num_col in ["No.","ä¾¡æ ¼ (ä¸‡å††)","å°‚æœ‰é¢ç© (ã¡)","ã¡å˜ä¾¡ (ä¸‡å††/ã¡)","åªå˜ä¾¡ (ä¸‡å††/åª)","äº¤é€š (åˆ†)","ç®¡ç†è²» (å††/æœˆ)"]:
        if num_col in df.columns:
            df[num_col] = pd.to_numeric(df[num_col], errors="coerce")
    return df

# =========================
# æˆ¸å»ºï¼ˆãƒ´ã‚£ãƒ©ï¼‰
# =========================
VILLA_COLUMNS = [
    "No.",
    "ç‰©ä»¶ç•ªå·",
    "ç‰©ä»¶ç¨®ç›®",
    "åœŸåœ°é¢ç© (ã¡)",
    "æ‰€åœ¨åœ°",
    "å–å¼•æ…‹æ§˜",
    "ä¾¡æ ¼ (ä¸‡å††)",
    "ç”¨é€”åœ°åŸŸ",
    "å»ºç‰©é¢ç© (ã¡)",
    "ã¡å˜ä¾¡ (ä¸‡å††/ã¡)",
    "é–“å–",
    "å–å¼•çŠ¶æ³",
    "æ¥é“çŠ¶æ³",
    "æ²¿ç·šé§…",
    "äº¤é€š (åˆ†)",
    "æ¥é“ï¼‘",
    "å•†å·",
    "ç¯‰å¹´æœˆ (YYYY-MM)",
    "é›»è©±ç•ªå·",
    "å…¥åŠ›æ—¥ (YYYYMMDD)",
]
_VILLA_ALIASES = {
    "No.": "No.",
    "ç‰©ä»¶ç•ªå·": "ç‰©ä»¶ç•ªå·",
    "ç‰©ä»¶ç¨®ç›®": "ç‰©ä»¶ç¨®ç›®",
    "åœŸåœ°é¢ç©": "åœŸåœ°é¢ç© (ã¡)",
    "æ‰€åœ¨åœ°": "æ‰€åœ¨åœ°",
    "å–å¼•æ…‹æ§˜": "å–å¼•æ…‹æ§˜",
    "ä¾¡æ ¼": "ä¾¡æ ¼ (ä¸‡å††)",
    "ç”¨é€”åœ°åŸŸ": "ç”¨é€”åœ°åŸŸ",
    "å»ºç‰©é¢ç©": "å»ºç‰©é¢ç© (ã¡)",
    "é–“å–": "é–“å–",
    "å–å¼•çŠ¶æ³": "å–å¼•çŠ¶æ³",
    "æ¥é“çŠ¶æ³": "æ¥é“çŠ¶æ³",
    "æ²¿ç·šé§…": "æ²¿ç·šé§…",
    "äº¤é€š": "äº¤é€š (åˆ†)",
    "æ¥é“ï¼‘": "æ¥é“ï¼‘",
    "å•†å·": "å•†å·",
    "ç¯‰å¹´æœˆ": "ç¯‰å¹´æœˆ (YYYY-MM)",
    "é›»è©±ç•ªå·": "é›»è©±ç•ªå·",
}

def parse_villa_html_to_df(html: str) -> pd.DataFrame:
    soup = BeautifulSoup(html, "lxml")
    table = _find_table_root(soup)
    if not table:
        return pd.DataFrame(columns=VILLA_COLUMNS)

    raw_rows = _rows_from_grid_table(table)
    records = []
    for rr in raw_rows:
        rec = {k: None for k in VILLA_COLUMNS}
        mapped = {}
        for k, v in rr.items():
            key = _VILLA_ALIASES.get(k)
            if key:
                mapped[key] = v

        # æ–‡å­—åˆ—ã®ã¾ã¾
        for key in ["No.","ç‰©ä»¶ç•ªå·","ç‰©ä»¶ç¨®ç›®","æ‰€åœ¨åœ°","å–å¼•æ…‹æ§˜","ç”¨é€”åœ°åŸŸ",
                    "é–“å–","å–å¼•çŠ¶æ³","æ¥é“çŠ¶æ³","æ²¿ç·šé§…","æ¥é“ï¼‘","å•†å·","é›»è©±ç•ªå·"]:
            rec[key] = mapped.get(key)

        # æ­£è¦åŒ–
        rec["ä¾¡æ ¼ (ä¸‡å††)"] = _clean_price_million_yen(mapped.get("ä¾¡æ ¼ (ä¸‡å††)"))
        rec["åœŸåœ°é¢ç© (ã¡)"] = _clean_area_sqm(mapped.get("åœŸåœ°é¢ç© (ã¡)"))
        rec["å»ºç‰©é¢ç© (ã¡)"] = _clean_area_sqm(mapped.get("å»ºç‰©é¢ç© (ã¡)"))
        rec["äº¤é€š (åˆ†)"] = _clean_minutes(mapped.get("äº¤é€š (åˆ†)"))
        rec["ç¯‰å¹´æœˆ (YYYY-MM)"] = _clean_yyyymm_from_jp(mapped.get("ç¯‰å¹´æœˆ (YYYY-MM)"))

        # ã¡å˜ä¾¡ã‚’è¨ˆç®—ï¼ˆä¾¡æ ¼ / å»ºç‰©é¢ç©ï¼‰
        if rec["ä¾¡æ ¼ (ä¸‡å††)"] and rec["å»ºç‰©é¢ç© (ã¡)"]:
            rec["ã¡å˜ä¾¡ (ä¸‡å††/ã¡)"] = rec["ä¾¡æ ¼ (ä¸‡å††)"] / rec["å»ºç‰©é¢ç© (ã¡)"]

        # å…¥åŠ›æ—¥
        rec["å…¥åŠ›æ—¥ (YYYYMMDD)"] = _get_today_yyyymmdd()

        records.append(rec)

    df = pd.DataFrame(records, columns=VILLA_COLUMNS)
    for num_col in ["No.","ä¾¡æ ¼ (ä¸‡å††)","åœŸåœ°é¢ç© (ã¡)","å»ºç‰©é¢ç© (ã¡)","ã¡å˜ä¾¡ (ä¸‡å††/ã¡)","äº¤é€š (åˆ†)"]:
        if num_col in df.columns:
            df[num_col] = pd.to_numeric(df[num_col], errors="coerce")
    return df

# =========================
# UI
# =========================
st.title("ä¸å‹•ç”£ãƒ†ãƒ¼ãƒ–ãƒ«ï¼šè²¼ã‚Šä»˜ã‘ â†’ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ â†’ Excel")

# Initialize session state
if 'tab1_df_apt' not in st.session_state:
    st.session_state.tab1_df_apt = None
if 'tab1_df_vil' not in st.session_state:
    st.session_state.tab1_df_vil = None
if 'tab2_df_apt' not in st.session_state:
    st.session_state.tab2_df_apt = None
if 'tab3_df_vil' not in st.session_state:
    st.session_state.tab3_df_vil = None

tab1, tab2, tab3, tab4 = st.tabs(["WEBå…¨ä½“ã‹ã‚‰æŠ½å‡º", "ãƒãƒ³ã‚·ãƒ§ãƒ³ / åŒºåˆ†", "æˆ¸å»ºï¼ˆãƒ´ã‚£ãƒ©ï¼‰", "ä¸€æ‹¬ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"])

with tab1:
    st.subheader("WEBãƒšãƒ¼ã‚¸å…¨ä½“ã‹ã‚‰è‡ªå‹•æŠ½å‡º")
    st.markdown("**ä½¿ã„æ–¹:** ãƒ–ãƒ©ã‚¦ã‚¶ã§å¯¾è±¡ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã€å³ã‚¯ãƒªãƒƒã‚¯ â†’ ã€Œãƒšãƒ¼ã‚¸ã®ã‚½ãƒ¼ã‚¹ã‚’è¡¨ç¤ºã€ â†’ å…¨ã¦ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä¸‹è¨˜ã«è²¼ã‚Šä»˜ã‘")
    full_html = st.text_area("WEBãƒšãƒ¼ã‚¸å…¨ä½“ã®HTMLã‚’è²¼ã‚Šä»˜ã‘", height=300, key="full_html")
    if st.button("ãƒ†ãƒ¼ãƒ–ãƒ«æŠ½å‡ºãƒ»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
        if not full_html.strip():
            st.warning("HTMLã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚")
        else:
            soup = BeautifulSoup(full_html, "lxml")
            apt_table, villa_table = _find_all_tables(soup)
            
            if not apt_table and not villa_table:
                st.error("âŒ ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚HTMLã®æ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                st.session_state.tab1_df_apt = None
                st.session_state.tab1_df_vil = None
            else:
                # Parse and store in session state
                st.session_state.tab1_df_apt = parse_apartment_html_to_df(str(apt_table)) if apt_table else pd.DataFrame()
                st.session_state.tab1_df_vil = parse_villa_html_to_df(str(villa_table)) if villa_table else pd.DataFrame()
                
                # Show what we found
                info_msg = "âœ… æ¤œå‡ºã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«: "
                if apt_table:
                    info_msg += "ãƒãƒ³ã‚·ãƒ§ãƒ³/åŒºåˆ† "
                if villa_table:
                    info_msg += "æˆ¸å»ºï¼ˆãƒ´ã‚£ãƒ©ï¼‰"
                st.success(info_msg)
                st.rerun()
    
    # Display stored data
    if st.session_state.tab1_df_apt is not None or st.session_state.tab1_df_vil is not None:
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ãƒãƒ³ã‚·ãƒ§ãƒ³/åŒºåˆ†ãƒ‡ãƒ¼ã‚¿")
            df_apt = st.session_state.tab1_df_apt
            if df_apt is not None and not df_apt.empty:
                st.success(f"{len(df_apt)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
                st.dataframe(df_apt, width='stretch', height=300)
            else:
                st.info("ãƒãƒ³ã‚·ãƒ§ãƒ³/åŒºåˆ†ãƒ‡ãƒ¼ã‚¿ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        with col2:
            st.markdown("#### æˆ¸å»ºï¼ˆãƒ´ã‚£ãƒ©ï¼‰ãƒ‡ãƒ¼ã‚¿")
            df_vil = st.session_state.tab1_df_vil
            if df_vil is not None and not df_vil.empty:
                st.success(f"{len(df_vil)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
                st.dataframe(df_vil, width='stretch', height=300)
            else:
                st.info("æˆ¸å»ºï¼ˆãƒ´ã‚£ãƒ©ï¼‰ãƒ‡ãƒ¼ã‚¿ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        # Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        df_apt = st.session_state.tab1_df_apt if st.session_state.tab1_df_apt is not None else pd.DataFrame()
        df_vil = st.session_state.tab1_df_vil if st.session_state.tab1_df_vil is not None else pd.DataFrame()
        
        if not df_apt.empty or not df_vil.empty:
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
                if not df_apt.empty:
                    df_apt.to_excel(writer, sheet_name="apartments", index=False)
                if not df_vil.empty:
                    df_vil.to_excel(writer, sheet_name="villas", index=False)
            st.download_button(
                label="ğŸ“¥ æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ã‚’Excelã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=buffer.getvalue(),
                file_name="extracted_data.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )

with tab2:
    st.subheader("ãƒãƒ³ã‚·ãƒ§ãƒ³ / åŒºåˆ†ï¼ˆHTMLã‚’è²¼ã‚Šä»˜ã‘ï¼‰")
    apt_html = st.text_area("ã“ã“ã«HTMLã‚’è²¼ã‚Šä»˜ã‘", height=240, key="apt_html")
    colp1, colp2 = st.columns(2)
    with colp1:
        if st.button("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆãƒãƒ³ã‚·ãƒ§ãƒ³ï¼‰"):
            st.session_state.tab2_df_apt = parse_apartment_html_to_df(apt_html)
            st.rerun()
    with colp2:
        if st.button("Excel ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒãƒ³ã‚·ãƒ§ãƒ³ï¼‰"):
            if st.session_state.tab2_df_apt is None:
                st.session_state.tab2_df_apt = parse_apartment_html_to_df(apt_html)
                st.rerun()
    
    if st.session_state.tab2_df_apt is not None:
        df_apt = st.session_state.tab2_df_apt
        if not df_apt.empty:
            st.dataframe(df_apt, width='stretch')
            
            # Download button
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
                df_apt.to_excel(writer, sheet_name="apartments", index=False)
            st.download_button(
                label="apartments.xlsx ã‚’ä¿å­˜",
                data=buffer.getvalue(),
                file_name="apartments.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )
        else:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚HTMLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

with tab3:
    st.subheader("æˆ¸å»ºï¼ˆãƒ´ã‚£ãƒ©ï¼‰ï¼ˆHTMLã‚’è²¼ã‚Šä»˜ã‘ï¼‰")
    villa_html = st.text_area("ã“ã“ã«HTMLã‚’è²¼ã‚Šä»˜ã‘", height=240, key="villa_html")
    colv1, colv2 = st.columns(2)
    with colv1:
        if st.button("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæˆ¸å»ºï¼‰"):
            st.session_state.tab3_df_vil = parse_villa_html_to_df(villa_html)
            st.rerun()
    with colv2:
        if st.button("Excel ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæˆ¸å»ºï¼‰"):
            if st.session_state.tab3_df_vil is None:
                st.session_state.tab3_df_vil = parse_villa_html_to_df(villa_html)
                st.rerun()
    
    if st.session_state.tab3_df_vil is not None:
        df_vil = st.session_state.tab3_df_vil
        if not df_vil.empty:
            st.dataframe(df_vil, width='stretch')
            
            # Download button
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
                df_vil.to_excel(writer, sheet_name="villas", index=False)
            st.download_button(
                label="villas.xlsx ã‚’ä¿å­˜",
                data=buffer.getvalue(),
                file_name="villas.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )
        else:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚HTMLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

with tab4:
    st.subheader("ãƒãƒ³ã‚·ãƒ§ãƒ³ + æˆ¸å»º ã‚’1ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¾ã¨ã‚ã¦å‡ºåŠ›")
    apt_html2 = st.text_area("ãƒãƒ³ã‚·ãƒ§ãƒ³HTML", height=180, key="apt_html_bulk")
    villa_html2 = st.text_area("æˆ¸å»ºHTML", height=180, key="villa_html_bulk")
    if st.button("ä¸€æ‹¬Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
        df_apt2 = parse_apartment_html_to_df(apt_html2)
        df_vil2 = parse_villa_html_to_df(villa_html2)
        if df_apt2.empty and df_vil2.empty:
            st.warning("ã©ã¡ã‚‰ã®HTMLã«ã‚‚ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
                if not df_apt2.empty:
                    df_apt2.to_excel(writer, sheet_name="apartments", index=False)
                if not df_vil2.empty:
                    df_vil2.to_excel(writer, sheet_name="villas", index=False)
            st.download_button(
                label="export_all.xlsx ã‚’ä¿å­˜",
                data=buffer.getvalue(),
                file_name="export_all.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )
